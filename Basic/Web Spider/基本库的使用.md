一、urllib

urllib是Python内置的HTTP请求库，不需要额外安装即可使用。
urllib库包含了4个模块：

    1.1、request：最基本的HTTP请求模块，可以用来模拟发送请求。
                  只需要给库方法传入URL以及额外的参数，就可以模拟浏览器访问网址。
   
    1.2、error：异常处理模块，如果出现请求错误，可以捕获这些异常，然后进行重试或其他操作以保证程序不会意外终止。
   
    1.3、parse：工具模块，提供了许多URL处理方法，比如拆分、解析、合并等。
   
    1.4、robotparser：主要是用来识别网站的robots.txt文件，然后判断哪些网站可以爬，哪些网站不可以爬，用得比较少。
   
1、发送请求

使用urllib的request模块，可以方便地实现请求地发送并得到响应。

1.1、urlopen()方法
是urllib.request()模块提供的最基本的构造HTTP请求的方法，利用它可以模拟浏览器的一个请求发起过程。同时还带有处理授权验证(authenticaton)、重定向(redirection)、浏览器Cookies以及其他内容。利用最基本的urlopen()方法，可以完成最基本的简单网页的GET请求抓取。

urlopen()方法抓取网页源码(包括链接、图片地址、文本信息)后，可以利用read()方法得到返回的网页内容。
    
urlopen()的API用法：  

urllib.request.urlopen(url, data=None, [timeout]*, cafile=None, capath=None, cadefault=False, context=None)  
    
    1.2.1、data参数
           可选择是否添加该参数。若添加，需要使用bytes()方法将参数转化为字节流编码格式的内容，即bytes类型。
           另外，如果传递了该参数，则请求方式应从GET方式给位POST方式。
    1.2.2、timeout参数
           用于设置超时时间，单位为秒。如果请求超过了设置的这个时间，还没得到响应，就会抛出异常。
           如果不指定该参数，就会使用全局默认时间。
           支持HTTP、HTTPS、FTP请求。
               
    1.2.3、context参数
           必须是ssl.SSLConText类型，用来指定SSL设置。
    1.2.4、cafile参数和capath参数
           分别用来指定CA证书和它的路径，在请求HTTPS链接时会有用。
    2.2.5、cadefailt参数
           默认值为False，现已弃用。

1.3、Request

利用urlopen()方法只能实现最基本请求的发起，但这几个简单的参数并不足以构建一个完整的请求。如果请求中需加入Headers等信息，就要利用更强大的Request类来构建。

利用Request()方法，一方面可以将请求独立成一个对象，另一方面可以更加丰富和灵活地配置参数。
    
    例：
    request = urllib.request.Request(URL)
    
    reponse = urllib.request.urlopen(request)
Request的构造方法:  

    class urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)

    (1)、参数url是必传参数，用于请求URL，其他都为选传。
    
    (2)、参数data，如果要传，必须传bytes(字节流)类型的。如果它是字典，可以先用urllib.parse模块中的urlencode()编码
    
    (3)、参数headers是请求头，是一个字典。可以在构建请求时通过headers参数直接构建。
         添加请求头最常见的方法时通过修改User-Agent来伪装浏览器，默认的User-Agent是Python—urllib。
         
    (4)、参数origin_req_host指的是请求方的host名称或者IP地址。
    
    (5)、参数unverifiable表示这个请求是否是无法验证的，默认是False，意思是用户没有足够的权限来选择接受这个请求的结果。
    
    (6)、参数method是一个字符串，用来指示请求使用的方法，比如POST、GET、PUT等。

1.4、Handler

用于一些更加高级的操作，比如Cookies处理，代理设置等。可以将其理解为各种处理器，有专门处理登陆验证的，有处理Cookies的，有处理代理设置的。利用它们，几乎可以做到HTTP请求中的所有事情。

1.4.1、BaseHandler类，是所有其他Handler的父类，提供了最基本的方法，例如default_open()、protocol_request()等。
    
     BaseHandler的子类：
     (1)、HTTPDefaultErrorHandler：用于处理HTTP响应错误，错误都会抛出HTTPError类型的异常。
     
     (2)、HTTPRedirectHandler：用于处理重定向。
     
     (3)、HTTPCookieProcessor：用于处理Cookies。
     
     (4)、ProxyHandler：用于设置代理，默认代理为空。
     
     (5)、HTTPPasswordMgr：用于管理密码，它维护了用户名和密码的表。
     
     (6)、HTTPBasicAuthHandler：用于管理认证，如果一个链接打开时需要认证，那么可以用它来解决认证问题。
     
     ......
     
1.5、OpenerDirector类

Request和urlop()封装好的极其常用的请求方法，利用它们可以完成基本的请求。为了实现更高级的功能，需要深入一层地进行配置，使用更底层的实例来完成操作，因此引入OpenerDirector类。OpenerDirector可以称为Opener。   
Opener可以使用open()方法，返回的类型与urlopen()一致。Opener与Handler的关系，简而言之，就是利用Handler来构建Opener。

......

2、处理异常

urllib的error模块定义了由request模块产生的异常。如果出现问题，request模块便会抛出error模块中定义的异常。

2.1、URLError

URLError类来自urllib库的error模块，它继承自OSError类，是error类异常处理模块的基类，由request模块产生的异常都可以通过捕获这个类来处理。
它具有一个属性reason，即返回错误的原因。

    例：
    from urllib import request, error
    try:
        response = request.urlopen(URL)
    except error.URLError as e:
        print(e.reason)
若URL不存在，抛出异常，会输出结果：
    
       Not Found
通过这样的操作，可以避免程序异常终止，同时异常得到了有效处理。

2.2、HTTPError

是URLError的子类，专门用来处理HTTP请求错误，比如认证请求失败等。有如下三个属性。

    (1)、code：返回HTTP状态码，比如404表示网页不存在，500表示服务器内部错误等。
    
    (2)、reason：同父类一样，用于返回错误的原因。
    
    (3)、headers：返回请求头。
    
3、解析链接

urllib库提供的parse模块，定义了处理URL的标准接口，例如实现URL各部分的抽取、合并以及链接转换。它支持如下协议的URL处理：file、ftp、gopther、hdl、http、https、imap、mailto、mms、news、nntp、prospero、rsync、rtsp、sftp、sip、sips、snews、svn、svn+ssh、telnet和wais。

3.1、urlparse()

该方法可以实现URL的识别和分段。

    例：
    from urllib.parse import urlparse
 
    result = urlparse('http://www.baidu.com/index.html;user?id=5#comment')
    print(type(result), result)
这里利用urlparse()方法进行了一个URL的解析，首先，输出了解析结果的类型，然后将结果也输出。

    结果：
    <class 'urllib.parse.ParseResult'>
    ParseResult(scheme='http', netloc='www.baidu.com', path='/index.html', params='user', query='id=5', fragment='comment')
返回结果是一个ParseResult类型的对象，它包含6部分，scheme、netloc、path、params、query和fragment。

观察URL：
    
    http://www.baidu.com/index.html;user?id=5#comment
可以发现，urlparse()方法将其拆分成了6部分。大体观察可以发现，解析时有特定的分隔符。比如，://前面的就是scheme，代表协议；第一个/前面便是netloc，即域名；分号;前面是params，代表参数。

可以得出一个标准的链接格式：

    scheme://netloc/path;parameters?query#fragment
    
一个标准的URL都会符合这个规则，利用urlparse()方法可以将它拆分开来。

urlparse()方法的API用法：

urllib.parse.urlparse(urlstring, scheme='', allow_fragments=True)

    (1)、urlstring：必填项，即待解析的URL.
    
    (2)、scheme：默认协议(如http或https等)。如果这个链接没有带协议信息，会将默认这个作为默认协议(https)。
    
    (3)、allow_fragments：即是否忽略fragment。如果它被设置为False，fragment部分就会被忽略，
         它会被解析为path、parameters或者query的一部分，而fragment部分为空。
         
3.2、urlunparse()

urlunparse()是urlparse()的对立方法。它接受的参数是一个可迭代对象，但是它的长度必须是6，否则会抛出参数数量不足或者过多的问题。

    例：
    from urllib.parse import urlunparse
 
    data = ['http', 'www.baidu.com', 'index.html', 'user', 'a=6', 'comment']
    print(urlunparse(data))
    
    结果如下：	
    http://www.baidu.com/index.html;user?a=6#comment
这样就可以成功实现URL的构造。

3.3、urlsplit()

和urlparse()方法非常相似，只不过它不再单独解析params这一部分，只返回5个结果。上面例子中的params会合并到path中。

    例：
    from urllib.parse import urlsplit
 
    result = urlsplit('http://www.baidu.com/index.html;user?id=5#comment')
    print(result)
    
    结果如下：
    SplitResult(scheme='http', netloc='www.baidu.com', path='/index.html;user', query='id=5', fragment='comment')
返回结果是SplitResult，它其实是一个元组类型，既可以用属性获取值，也可以用索引来获取。 
